{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lujainAziz/LujainAlmajyul-it326/blob/main/Phase2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07ad32d2",
      "metadata": {
        "id": "07ad32d2"
      },
      "source": [
        "# IT326 – Phase 2: Data Summarization & Preprocessing\n",
        "\n",
        "This notebook follows the Phase 2 requirements:\n",
        "- Data Analysis (summaries, distributions, missing values, class distribution, outliers & boxplots, at least 3 plots)\n",
        "- Data Preprocessing (apply at least three techniques other than removal/splitting: normalization, discretization, noise removal)\n",
        "\n",
        "**Dataset path:** `/mnt/data/Dataset/Raw_dataset.csv`\n",
        "**Preprocessed output:** `/mnt/data/Dataset/Preprocessed_dataset.csv`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ee4cfd7",
      "metadata": {
        "id": "2ee4cfd7"
      },
      "source": [
        "## Contents\n",
        "1. [Setup](#setup)\n",
        "2. [Data Overview](#overview)\n",
        "3. [Data Analysis](#analysis)\n",
        "   - 3.1 Missing Values\n",
        "   - 3.2 Statistical Summary (Five-number summary)\n",
        "   - 3.3 Distributions (Histograms)\n",
        "   - 3.4 Boxplots & Outliers\n",
        "   - 3.5 Class Label Distribution\n",
        "   - 3.6 Example Scatter Plot\n",
        "4. [Data Preprocessing](#preprocessing)\n",
        "   - 4.1 Outlier Treatment (IQR Capping)\n",
        "   - 4.2 Normalization (Min-Max)\n",
        "   - 4.3 Discretization (GPA → Low/Medium/High)\n",
        "   - 4.4 (Optional) Feature Selection note\n",
        "   - 4.5 Save Preprocessed Dataset\n",
        "5. [Before vs After Snapshot](#snapshot)\n",
        "6. [Notes & Justification](#notes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "efdb2378",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "efdb2378",
        "outputId": "f4fada31-c46d-4a9e-b452-e8657b7d0c10"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/mnt/data/Dataset/Raw_dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1781566264.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mPREPROC_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"/mnt/data/Dataset/Preprocessed_dataset.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRAW_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/Dataset/Raw_dataset.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "RAW_PATH = r\"/mnt/data/Dataset/Raw_dataset.csv\"\n",
        "PREPROC_PATH = r\"/mnt/data/Dataset/Preprocessed_dataset.csv\"\n",
        "\n",
        "df = pd.read_csv(RAW_PATH)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f14f94c8",
      "metadata": {
        "id": "f14f94c8"
      },
      "source": [
        "## 2. Data Overview  <a id='overview'></a>\n",
        "- Print info, dtypes, shape, and a small sample.\n",
        "- Confirm the class attribute and its value counts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c915c42a",
      "metadata": {
        "id": "c915c42a"
      },
      "outputs": [],
      "source": [
        "print('\\nDataset Info:')\n",
        "df.info()\n",
        "print('\\nDtypes:')\n",
        "print(df.dtypes)\n",
        "print('\\nShape:', df.shape)\n",
        "display(df.head())\n",
        "\n",
        "label_col = 'GradeClass'\n",
        "print('\\nClass counts:')\n",
        "print(df[label_col].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68677672",
      "metadata": {
        "id": "68677672"
      },
      "source": [
        "## 3. Data Analysis  <a id='analysis'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34160d80",
      "metadata": {
        "id": "34160d80"
      },
      "outputs": [],
      "source": [
        "# 3.1 Missing Values\n",
        "missing_counts = df.isna().sum().sort_values(ascending=False)\n",
        "display(missing_counts.to_frame('Missing'))\n",
        "print('Any missing? ', df.isna().any().any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37ad4612",
      "metadata": {
        "id": "37ad4612"
      },
      "outputs": [],
      "source": [
        "# 3.2 Statistical Summary\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "desc = df[numeric_cols].describe(percentiles=[0.25,0.5,0.75]).T\n",
        "display(desc[['min','25%','50%','75%','max','mean','std']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5cad55a",
      "metadata": {
        "id": "e5cad55a"
      },
      "outputs": [],
      "source": [
        "# 3.3 Distributions (Histograms) – choose a few key numeric columns\n",
        "cols_to_plot = [c for c in ['GPA','Absences','StudyTimeWeekly'] if c in df.columns]\n",
        "for c in cols_to_plot:\n",
        "    plt.figure()\n",
        "    df[c].plot(kind='hist', bins=30, title=f'Histogram of {c}')\n",
        "    plt.xlabel(c)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7242da23",
      "metadata": {
        "id": "7242da23"
      },
      "outputs": [],
      "source": [
        "# 3.4 Boxplots & Outliers (IQR logic preview)\n",
        "box_cols = [c for c in ['GPA','Absences','StudyTimeWeekly'] if c in df.columns]\n",
        "for c in box_cols:\n",
        "    plt.figure()\n",
        "    df[c].plot(kind='box', title=f'Boxplot of {c}')\n",
        "    plt.ylabel(c)\n",
        "    plt.show()\n",
        "\n",
        "def iqr_bounds(s, k=1.5):\n",
        "    q1, q3 = s.quantile(0.25), s.quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    return q1 - k*iqr, q3 + k*iqr\n",
        "\n",
        "for c in box_cols:\n",
        "    lo, hi = iqr_bounds(df[c].astype(float))\n",
        "    outliers = ((df[c] < lo) | (df[c] > hi)).sum()\n",
        "    print(f'{c}: lower={lo:.3f}, upper={hi:.3f}, outliers={outliers}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd741260",
      "metadata": {
        "id": "cd741260"
      },
      "outputs": [],
      "source": [
        "# 3.5 Class Label Distribution (Bar Plot)\n",
        "counts = df['GradeClass'].value_counts().sort_index()\n",
        "plt.figure()\n",
        "counts.plot(kind='bar', title='Class Label Distribution (GradeClass)')\n",
        "plt.xlabel('GradeClass')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80c78d84",
      "metadata": {
        "id": "80c78d84"
      },
      "outputs": [],
      "source": [
        "# 3.6 Example Scatter Plot: GPA vs StudyTimeWeekly\n",
        "if set(['GPA','StudyTimeWeekly']).issubset(df.columns):\n",
        "    plt.figure()\n",
        "    plt.scatter(df['StudyTimeWeekly'], df['GPA'])\n",
        "    plt.xlabel('StudyTimeWeekly')\n",
        "    plt.ylabel('GPA')\n",
        "    plt.title('Scatter: GPA vs StudyTimeWeekly')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3ab53a6",
      "metadata": {
        "id": "d3ab53a6"
      },
      "source": [
        "## 4. Data Preprocessing  <a id='preprocessing'></a>\n",
        "We apply at least three techniques: **Outlier Treatment (IQR capping)**, **Normalization (Min-Max)**, and **Discretization (GPA → bins)**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79a4684e",
      "metadata": {
        "id": "79a4684e"
      },
      "outputs": [],
      "source": [
        "# 4.1 Outlier Treatment (IQR Capping)\n",
        "df_prep = df.copy()\n",
        "cont_cols = [c for c in ['Age','StudyTimeWeekly','Absences','GPA'] if c in df_prep.columns]\n",
        "def iqr_cap(series, k=1.5):\n",
        "    q1 = series.quantile(0.25)\n",
        "    q3 = series.quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower = q1 - k * iqr\n",
        "    upper = q3 + k * iqr\n",
        "    return series.clip(lower=lower, upper=upper)\n",
        "for c in cont_cols:\n",
        "    df_prep[f'{c}_capped'] = iqr_cap(df_prep[c].astype(float))\n",
        "df_prep.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2179b12",
      "metadata": {
        "id": "f2179b12"
      },
      "outputs": [],
      "source": [
        "# 4.2 Normalization (Min-Max) on capped columns\n",
        "def minmax_scale(s):\n",
        "    mn, mx = s.min(), s.max()\n",
        "    if mx == mn:\n",
        "        return pd.Series(np.zeros_like(s), index=s.index)\n",
        "    return (s - mn) / (mx - mn)\n",
        "for c in [f'{x}_capped' for x in cont_cols]:\n",
        "    df_prep[f'{c.replace(\"_capped\", \"_minmax\")}'] = minmax_scale(df_prep[c].astype(float))\n",
        "df_prep[[c for c in df_prep.columns if c.endswith('_minmax')]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0430ccbe",
      "metadata": {
        "id": "0430ccbe"
      },
      "outputs": [],
      "source": [
        "# 4.3 Discretization (GPA → Low/Medium/High) using quantiles\n",
        "if 'GPA' in df_prep.columns:\n",
        "    q = df_prep['GPA'].quantile([0.33, 0.66]).values\n",
        "    bins = [-np.inf, q[0], q[1], np.inf]\n",
        "    labels = ['Low','Medium','High']\n",
        "    df_prep['GPA_Bin'] = pd.cut(df_prep['GPA'], bins=bins, labels=labels)\n",
        "df_prep['GPA_Bin'].value_counts(dropna=False) if 'GPA_Bin' in df_prep.columns else 'GPA not found'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51fd6a6b",
      "metadata": {
        "id": "51fd6a6b"
      },
      "source": [
        "### 4.4 (Optional) Feature Selection note\n",
        "- For **Decision Trees** (Phase 3), numerical scaling is not required but harmless.\n",
        "- We do **not** drop features here to keep Phase 3 flexible.\n",
        "- We will exclude obvious identifiers (e.g., `StudentID`) during model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b545a3d8",
      "metadata": {
        "id": "b545a3d8"
      },
      "outputs": [],
      "source": [
        "# 4.5 Save Preprocessed Dataset\n",
        "import os\n",
        "os.makedirs(os.path.dirname(PREPROC_PATH), exist_ok=True)\n",
        "df_prep.to_csv(PREPROC_PATH, index=False)\n",
        "print('Saved:', PREPROC_PATH)\n",
        "df_prep.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "207fe980",
      "metadata": {
        "id": "207fe980"
      },
      "source": [
        "## 5. Before vs After Snapshot  <a id='snapshot'></a>\n",
        "- The table below contrasts a few rows of raw vs preprocessed columns to show the effect of capping and scaling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edbf7622",
      "metadata": {
        "id": "edbf7622"
      },
      "outputs": [],
      "source": [
        "cols_show = []\n",
        "for base in ['GPA','Absences','StudyTimeWeekly']:\n",
        "    for suffix in ['', '_capped', '_minmax']:\n",
        "        col = base + suffix\n",
        "        if col in df_prep.columns:\n",
        "            cols_show.append(col)\n",
        "display(pd.concat([df[cols_show], df_prep[cols_show]], axis=1).head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de2b9865",
      "metadata": {
        "id": "de2b9865"
      },
      "source": [
        "## 6. Notes & Justification  <a id='notes'></a>\n",
        "- **Missing Values:** The dataset contains no missing values in the provided snapshot. We still confirm programmatically.\n",
        "- **Outliers:** IQR-based capping (winsorization) reduces the influence of extreme values in `Absences` and `StudyTimeWeekly`.\n",
        "- **Normalization:** Min-Max scaling is applied on capped continuous columns to bring them to [0,1], helping algorithms sensitive to scale.\n",
        "- **Discretization:** `GPA` is discretized into **Low/Medium/High** using quantiles to support interpretable analysis and optional modeling variants.\n",
        "- **No removal of raw columns:** We keep raw features intact to comply with the requirement of preserving the original dataset and to allow Phase 3 flexibility.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}